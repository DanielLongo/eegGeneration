{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_lab(fld1,fld2):\n",
    "    return np.array_equal(np.round(fld1),np.round(fld2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding files for \n",
    "label_dir = '/Users/jdunnmon/Research/projects/xmodal/eeg/results/run_logs/2018_11_01/22_10_36'\n",
    "seiz_file = 'metal_results_lpch_seizure.tsv'\n",
    "non_seiz_file = 'metal_results_lpch_non_seizure.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening empty file list\n",
    "with open('../EEG-sequence/file_markers/empty_file_names.txt','rb') as fl:\n",
    "    empty_files = pickle.load(fl)\n",
    "    \n",
    "# Loading silver label dict\n",
    "silver_label_dir = '../EEG-sequence/silver_labels/silver_dicts'\n",
    "silver_label_dict = {}\n",
    "for fn in os.listdir(silver_label_dir):\n",
    "    with open(os.path.join(silver_label_dir,fn),'rb') as fl:\n",
    "        tmp = pickle.load(fl)\n",
    "    silver_label_dict.update(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10028\n",
      "Number of samples: 32634\n",
      "Number of rows in dataframe: 3032\n"
     ]
    }
   ],
   "source": [
    "# Creating label dictionary\n",
    "train_file_list = []\n",
    "train_label_list = []\n",
    "data_df_all = pd.DataFrame()\n",
    "for data_file in [seiz_file, non_seiz_file]:\n",
    "    data_df = pd.read_csv(os.path.join(label_dir, data_file), sep='\\t',index_col=0)\n",
    "    #data_df = data_df.drop_duplicates(subset=['id'],keep='first').reset_index(drop=True)\n",
    "    #data_df = data_df.drop_duplicates(subset=['file_name'],keep='last').reset_index(drop=True)\n",
    "    print(f'Number of samples: {len(data_df)}')\n",
    "    #data_df.to_csv(os.path.join(label_dir, 'reduced_'+data_file),sep='\\t')\n",
    "    #train_file_list = train_file_list + [a.split('.')[0]+'.eeghdf' for a in data_df['file_name'].tolist()]\n",
    "    data_df_all = data_df_all.append(data_df.copy())\n",
    "#train_file_list_nonempty = [t for t in train_file_list if t not in empty_files]\n",
    "data_df_all['file_name'] = pd.Series([a.split('.')[0]+'.eeghdf' for a in data_df_all['file_name'].tolist()])\n",
    "data_df_all['text_mv_output'] = pd.Series([np.array(ast.literal_eval(a)) for a in data_df_all['text_mv_output']])\n",
    "data_df_all['text_gm_marginals'] = pd.Series([np.array(ast.literal_eval(a.replace(' ',','))) for a in data_df_all['text_gm_marginals']])\n",
    "data_df_all['gm_prob_abnorm'] = pd.Series([a[0] for a in data_df_all['text_gm_marginals']])\n",
    "data_df_all['mv_prob_abnorm'] = pd.Series([a[0] for a in data_df_all['text_mv_output']])\n",
    "data_df_all = data_df_all.loc[~data_df_all['file_name'].isin(empty_files)]\n",
    "data_df_all['silver_label'] = pd.Series(silver_label_dict.get(f,np.nan) for f in data_df_all['file_name'])\n",
    "#data_df_all = data_df_all.loc[[row['silver_label'][0] != -1 for ind,row in data_df_all.iterrows()])\n",
    "data_df_all = data_df_all.dropna(subset=['silver_label'])\n",
    "data_df_all['silver_label'] = pd.Series([row['silver_label'][0] for ind,row in data_df_all.iterrows()])\n",
    "data_df_all['id_count'] =  data_df_all.groupby(['id'])['id'].transform(\"count\")\n",
    "\n",
    "# dropping files with large number of signals\n",
    "data_df_all = data_df_all.loc[data_df_all['id_count']==1].reset_index(drop=True)\n",
    "\n",
    "#print(f'Number of files: {len(train_file_list)}')\n",
    "#print(f'Number of reduced files: {len(train_file_list_nonempty)}')\n",
    "print(f'Number of rows in dataframe: {len(data_df_all)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_file = data_df_all.groupby(['file_name'])\n",
    "df_gm_mean = df_by_file.gm_prob_abnorm.max()\n",
    "data_df_all['gm_agg'] = pd.Series([df_gm_mean[row['file_name']] for ind,row in data_df_all.iterrows()])\n",
    "data_df_all['silver_agg'] = pd.Series([df_gm_mean[row['file_name']] for ind,row in data_df_all.iterrows()])\n",
    "data_df_all['corr_pred'] = data_df_all.apply(lambda row: corr_lab(row['silver_label'], row['gm_agg_mean']),axis=1)\n",
    "\n",
    "\n",
    "df_incorrect = data_df_all[~data_df_all['corr_pred']]\n",
    "df_correct = data_df_all[data_df_all['corr_pred']]\n",
    "df_incorrect_by_file = df_incorrect.groupby(['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1138"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_incorrect)\n",
    "#Counter(df_incorrect_by_file['file_name'].agg('count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565.0"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df_incorrect['silver_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gm_pos = data_df_all.loc[data_df_all['gm_prob_abnorm']>0.5]\n",
    "df_gm_neg = data_df_all.loc[data_df_all['gm_prob_abnorm']<0.5]\n",
    "#df_gm_neg = data_df_all[]\n",
    "#df_filter = df_correct\n",
    "#df_filter = df_filter.loc[~df_filter['id'].isin(df_incorrect['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter = data_df_all.loc[data_df_all['id_count']==1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1564,\n",
       "         17: 19,\n",
       "         5: 74,\n",
       "         3: 108,\n",
       "         2: 324,\n",
       "         11: 33,\n",
       "         54: 7,\n",
       "         6: 70,\n",
       "         14: 22,\n",
       "         4: 94,\n",
       "         36: 6,\n",
       "         43: 1,\n",
       "         10: 40,\n",
       "         20: 13,\n",
       "         27: 11,\n",
       "         7: 57,\n",
       "         9: 56,\n",
       "         19: 22,\n",
       "         12: 36,\n",
       "         30: 13,\n",
       "         15: 19,\n",
       "         18: 15,\n",
       "         31: 6,\n",
       "         99: 2,\n",
       "         41: 6,\n",
       "         8: 54,\n",
       "         71: 2,\n",
       "         84: 2,\n",
       "         29: 10,\n",
       "         47: 3,\n",
       "         28: 19,\n",
       "         46: 4,\n",
       "         42: 2,\n",
       "         37: 5,\n",
       "         21: 13,\n",
       "         70: 1,\n",
       "         39: 6,\n",
       "         197: 1,\n",
       "         90: 1,\n",
       "         23: 22,\n",
       "         25: 18,\n",
       "         51: 1,\n",
       "         34: 5,\n",
       "         161: 1,\n",
       "         26: 9,\n",
       "         68: 3,\n",
       "         13: 29,\n",
       "         48: 2,\n",
       "         80: 3,\n",
       "         53: 2,\n",
       "         24: 14,\n",
       "         16: 12,\n",
       "         204: 1,\n",
       "         35: 3,\n",
       "         153: 1,\n",
       "         83: 3,\n",
       "         106: 1,\n",
       "         52: 3,\n",
       "         107: 2,\n",
       "         60: 1,\n",
       "         45: 5,\n",
       "         63: 2,\n",
       "         33: 16,\n",
       "         40: 2,\n",
       "         32: 3,\n",
       "         187: 1,\n",
       "         22: 5,\n",
       "         133: 1,\n",
       "         38: 5,\n",
       "         57: 1,\n",
       "         64: 1,\n",
       "         235: 1,\n",
       "         100: 1,\n",
       "         104: 1,\n",
       "         44: 2,\n",
       "         102: 2,\n",
       "         55: 1,\n",
       "         62: 1,\n",
       "         82: 3,\n",
       "         73: 1,\n",
       "         88: 2,\n",
       "         218: 1,\n",
       "         67: 1,\n",
       "         65: 1,\n",
       "         79: 1,\n",
       "         86: 1})"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_gm_pos.groupby('id')['file_name'].agg('count'))\n",
    "# Check how many filenames in incorrect and correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1670,\n",
       "         13: 34,\n",
       "         24: 8,\n",
       "         80: 2,\n",
       "         3: 125,\n",
       "         45: 5,\n",
       "         2: 281,\n",
       "         28: 8,\n",
       "         6: 84,\n",
       "         11: 33,\n",
       "         25: 11,\n",
       "         107: 1,\n",
       "         22: 9,\n",
       "         26: 9,\n",
       "         19: 10,\n",
       "         16: 15,\n",
       "         5: 97,\n",
       "         8: 71,\n",
       "         14: 32,\n",
       "         32: 6,\n",
       "         18: 18,\n",
       "         4: 97,\n",
       "         15: 28,\n",
       "         17: 17,\n",
       "         10: 45,\n",
       "         12: 43,\n",
       "         7: 55,\n",
       "         9: 45,\n",
       "         21: 12,\n",
       "         75: 4,\n",
       "         55: 1,\n",
       "         20: 12,\n",
       "         23: 12,\n",
       "         61: 1,\n",
       "         27: 6,\n",
       "         37: 6,\n",
       "         30: 6,\n",
       "         74: 1,\n",
       "         31: 7,\n",
       "         29: 7,\n",
       "         59: 4,\n",
       "         57: 1,\n",
       "         40: 3,\n",
       "         54: 2,\n",
       "         33: 6,\n",
       "         39: 7,\n",
       "         118: 2,\n",
       "         41: 3,\n",
       "         73: 3,\n",
       "         46: 2,\n",
       "         34: 9,\n",
       "         82: 1,\n",
       "         81: 2,\n",
       "         130: 1,\n",
       "         47: 1,\n",
       "         35: 5,\n",
       "         38: 4,\n",
       "         51: 2,\n",
       "         43: 5,\n",
       "         48: 1,\n",
       "         62: 1,\n",
       "         76: 1,\n",
       "         84: 1,\n",
       "         36: 3,\n",
       "         56: 1,\n",
       "         49: 1,\n",
       "         69: 1,\n",
       "         52: 1,\n",
       "         68: 1,\n",
       "         92: 1,\n",
       "         64: 1,\n",
       "         42: 2,\n",
       "         53: 1,\n",
       "         83: 1,\n",
       "         50: 1,\n",
       "         58: 2,\n",
       "         65: 1,\n",
       "         210: 1,\n",
       "         128: 1})"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_gm_neg.groupby('id')['file_name'].agg('count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14238"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_filter.loc[df_filter['file_name']=='DA0550IQ_1-1+.eeghdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17206 common files...\n"
     ]
    }
   ],
   "source": [
    "# Getting union of weak labels and silver labels\n",
    "common_files = list(set(silver_label_dict.keys()).intersection(set(data_df_all['file_name'])))\n",
    "data_df_all = data_df_all.loc[data_df_all['file_name'].isin(common_files)]\n",
    "print(f'{len(common_files)} common files...')\n",
    "\n",
    "# Creating weak label dicts\n",
    "gm_label_dict = dict(zip(data_df_all['file_name'],data_df_all['text_gm_marginals']))\n",
    "mv_label_dict = dict(zip(data_df_all['file_name'],data_df_all['text_mv_output']))\n",
    "gm_mean_dict = dict(zip(df_gm_mean.keys(),df_gm_mean.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating GM accuracy\n",
    "def binarize_marginal(m, cut):\n",
    "    if hasattr(m, \"__len__\"):\n",
    "        abnorm = m[0]\n",
    "    else:\n",
    "        abnorm = m\n",
    "        \n",
    "    if abnorm>cut:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "cutoff=0.5\n",
    "eval_filenames = common_files\n",
    "mv_labels = np.array([binarize_marginal(mv_label_dict[f],cutoff) for f in eval_filenames])\n",
    "gm_labels = np.array([binarize_marginal(gm_label_dict[f],cutoff) for f in eval_filenames])\n",
    "gm_mean = np.array([binarize_marginal(gm_mean_dict[f],cutoff) for f in eval_filenames])\n",
    "\n",
    "silver_labels = np.array([np.argmax(silver_label_dict[f])+1 for f in eval_filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.38      0.71      0.49      3468\n",
      "          2       0.91      0.71      0.79     13738\n",
      "\n",
      "avg / total       0.80      0.71      0.73     17206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from collections import Counter\n",
    "print(metrics.classification_report(silver_labels, gm_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.31      0.71      0.43      3468\n",
      "          2       0.89      0.60      0.72     13738\n",
      "\n",
      "avg / total       0.77      0.62      0.66     17206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(silver_labels, gm_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.36      0.78      0.49      3468\n",
      "          2       0.92      0.65      0.76     13738\n",
      "\n",
      "avg / total       0.81      0.67      0.71     17206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(silver_labels, mv_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 10729, 1: 3468})\n",
      "Counter({2: 9120, 1: 5077})\n",
      "Counter({2: 8343, 1: 5854})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(silver_labels))\n",
    "print(Counter(gm_labels))\n",
    "print(Counter(mv_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6904275551172783"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(silver_labels, gm_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "\n",
    "# Check on accuracy per signal\n",
    "# Try using max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_file = data_df_all.groupby(['file_name'])\n",
    "gm_mean = df_by_file.gm_prob_abnorm.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14197\n",
      "14197\n"
     ]
    }
   ],
   "source": [
    "print(len(common_files))\n",
    "print(len(gm_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.99462126e-01, 9.99462126e-01, 9.99462126e-01, ...,\n",
       "       3.14019686e-05, 1.08651700e-05, 9.98405970e-01])"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm_mean.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'AA12206J_1-1+.eeghdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-439-bc4401d3e118>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msm_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mky\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgm_mean_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mgm_mean_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mky\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mgm_label_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mky\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0msm_lst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mky\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'AA12206J_1-1+.eeghdf'"
     ]
    }
   ],
   "source": [
    "sm_lst = []\n",
    "for ky in gm_mean_dict.keys():\n",
    "    if gm_mean_dict[ky] != gm_label_dict[ky][0]:\n",
    "        sm_lst.append(ky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3888"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sm_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 13738, 2: 3468})"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_by_file['id'].agg('count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: False'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-465-0f5a169c7fbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_by_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_by_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'AA12206J_1-1+.eeghdf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Research/repos/anaconda3/anaconda3/envs/metal/lib/python3.6/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Column not found: {key}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: False'"
     ]
    }
   ],
   "source": [
    "df_by_file[df_by_file['file_name']=='AA12206J_1-1+.eeghdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_id = data_df_all.groupby(['id'])\n",
    "gm_id_max = df_by_id.gm_prob_abnorm.max()\n",
    "silver_id_max = df_by_id.silver_label.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.67      0.61      0.64      1713\n",
      "        1.0       0.54      0.60      0.57      1319\n",
      "\n",
      "avg / total       0.61      0.61      0.61      3032\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(silver_id_max, np.round(gm_id_max)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "001186a8-85f9-5738-9d5a-a52453a09d00    1.0\n",
      "0011a36f-0e3b-591c-8a97-6b6aa3ff7738    0.0\n",
      "001b681f-0742-5419-a3c7-07d09015a36c    0.0\n",
      "002e8443-4d7f-52fc-9c2b-e63798a8f440   -1.0\n",
      "0038079e-c09b-5494-a47c-fce14c3d4002   -1.0\n",
      "0058912d-2dec-5331-8c3c-ca0ac91b2f48    0.0\n",
      "006a9336-fa91-5e5c-90d2-bb04b034a551    0.0\n",
      "0071f36d-6c7d-50ee-9e28-e8e4bc0cf8c5   -1.0\n",
      "007af21f-c333-5789-9acc-0eb2ef8debc0    0.0\n",
      "008132db-9888-56ab-9906-998d8833073c    0.0\n",
      "0089e9a3-636a-56ce-a712-f966301e57db    0.0\n",
      "008ea0fd-c4c2-55b0-9b8a-cb83b50b710f    0.0\n",
      "009faa68-b25f-5e1b-929f-28f60d3f9936    0.0\n",
      "00a1b9e0-efa5-5701-8e2a-03a858ff5c36    0.0\n",
      "00a86267-cf1a-5942-95b4-814dabf9bef6    0.0\n",
      "00bb9e09-b463-55b3-976e-92221461ec36    0.0\n",
      "00fa1307-be62-5293-9a8e-d41a33deeddf    0.0\n",
      "01140362-b12d-55fc-90a2-985d980b3137   -1.0\n",
      "0134cd05-7ec9-5e98-bd1a-e776e1d2580a    0.0\n",
      "013de716-c7a6-5fbc-9a5b-27bf67bbb855    0.0\n",
      "0156902e-423a-5870-bf10-762fc122d1df    0.0\n",
      "01bd1c15-9469-5cc1-b81f-893b15767c38    1.0\n",
      "01c3b9ef-a18a-5fca-beee-396cdc81ca03    0.0\n",
      "01c4ea38-96bc-58fe-91b4-fb1864eedf27    0.0\n",
      "020bba89-6096-519c-b65b-9f983bb329d6    0.0\n",
      "021416a3-89c0-57cf-b74d-2ee2302b7f78    0.0\n",
      "0214c404-a0a6-5ecb-ae92-f541414de171    0.0\n",
      "023ed8d6-92f3-51f6-ba49-51f1cbc79ad0    0.0\n",
      "0244f5d6-6a2e-5459-8fdc-58f9aac4f97f    0.0\n",
      "0245f1b0-64b6-5865-a5ae-a527b6875a06    0.0\n",
      "                                       ... \n",
      "fd75975a-47cc-5054-864c-c30d231d0a09    1.0\n",
      "fd8bf55b-350a-5b8d-bf85-7779812b5aff    1.0\n",
      "fda0d062-0d87-5ade-bc87-a13b747f99c4    0.0\n",
      "fda34b11-1b94-503d-91df-897a44cb13f1   -1.0\n",
      "fdbc2573-d0db-5ebe-83f1-dd5589f3ade8    0.0\n",
      "fdd648aa-8fa0-578e-9967-4f68b86ca716    0.0\n",
      "fddc938c-f4bb-5512-b9f3-b80921a140b2   -1.0\n",
      "fdf955a1-0423-50f8-b674-07b77b492bc1   -1.0\n",
      "fe0281c1-8d86-56b7-ab17-74ff7d8ede15    1.0\n",
      "fe05102d-d7d2-54ea-988b-bf93423c2f63    0.0\n",
      "fe21a742-105f-52dd-8315-5b99b8fdc282    0.0\n",
      "fe3d2990-c835-5af0-a50a-976f8cffc30e    1.0\n",
      "fe4aedd6-a0d8-5ba5-a91a-af643cf3fc9a    0.0\n",
      "fe4d0662-9c4f-5e8f-83f2-2be432471326    0.0\n",
      "fe747631-ab34-55fa-8f33-49c34fa464e5    0.0\n",
      "fe7e3458-db7c-5b68-99fd-3e806070a64e    0.0\n",
      "fe9b95eb-9cdc-5fef-bc23-28c5dc1c7079    0.0\n",
      "fecd052c-5c69-5d4e-b060-be67fd117936   -1.0\n",
      "ff260859-c91f-528e-8618-32e96a213e06   -1.0\n",
      "ff2ce8c1-7aec-593d-861d-6bc265e98f89    0.0\n",
      "ff449ce2-53c5-5e79-9a4b-b77e8b9241fa    1.0\n",
      "ff5103c4-aceb-56a9-b0a3-34e78a542d40   -1.0\n",
      "ff533c75-8efb-5e71-ac1a-eed2b208cbd4    1.0\n",
      "ff6286c3-8303-562c-bc96-ebe32aca8bbf   -1.0\n",
      "ff66a90f-cb17-5fb7-943d-b2035b818319    0.0\n",
      "ff9b73bf-c16d-5604-9f51-313578ad38e3    0.0\n",
      "ff9bbc64-5edc-584e-a738-18f93ad96f2c   -1.0\n",
      "fff24a48-7454-59b5-9e29-b1c41267f924    0.0\n",
      "fff5d865-8249-511e-ac4f-fc5ae1e8d69a    0.0\n",
      "fffaae6f-fc45-5698-a221-9a45d911df0b    1.0\n",
      "Length: 3032, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_by_id.silver_label.max()-np.round(df_by_id.gm_prob_abnorm.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metal]",
   "language": "python",
   "name": "conda-env-metal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
